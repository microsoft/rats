{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Beginners Tutorial"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## \"Hello World\" Example\n","\n","Let's start writing the most simple pipeline that takes no inputs or outputs and prints\n","`\"Hello World\"` on screen.\n","\n","The first step is to write a *processor* with the printing functionality.\n","We need to define a `process` method with no input and no output.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class HelloWorld:\n","    def process(self) -> None:\n","        print(\"Hello World\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To create a pipeline and run it, we can use the following lines:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from oneml.processors import PipelineBuilder, PipelineRunner\n","\n","hello_world = PipelineBuilder.task(HelloWorld, \"hello_world\")  # creates a pipeline of single node\n","runner = PipelineRunner(hello_world)  # creates a runner for the given pipeline\n","runner()  # runs the pipeline"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## \"Diamond\" Pipeline Example\n","\n","Consider now we have four classes, i.e., `A`, `B`, `C` and `D` with some inputs and outputs and we\n","want to connect them following a diamond-based shape:\n","\n","```\n","  A           B <- A\n"," / \\          C <- A\n","B   C         D <- B\n"," \\ /          D <- C\n","  D\n","```\n","\n","We have the following classes and declared outputs:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Any, TypedDict\n","\n","AOutput = TypedDict(\"AOutput\", {\"Z1\": float, \"Z2\": float})\n","BOutput = TypedDict(\"BOutput\", {\"Z\": float})\n","COutput = TypedDict(\"COutput\", {\"Z\": float})\n","\n","\n","class A:\n","    def process(self) -> AOutput:\n","        ...\n","\n","\n","class B:\n","    def process(self, X: Any) -> BOutput:\n","        ...\n","\n","\n","class C:\n","    def process(self, X: Any) -> COutput:\n","        ...\n","\n","\n","class D:\n","    def process(self, X1: Any, X2: Any) -> None:\n","        ...\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*Processors* can have arbitrary inputs, in this case we have processors with empty, single, single\n","and two inputs, respectively.\n","\n","*Processors* declare their outputs too.\n","To declare outputs, the `process` method needs to return a mapping with variable names and values,\n","i.e., `Mapping[str, Any]`, or `None`.\n","`TypedDict` is a useful built-in type to declare the variable names and types, which we used to\n","specify that *processor* `A` returns two outputs, `B` and `C` return a single output, and `D`\n","returns nothing.\n","\n","Once we have written our *processor* classes, we need to create a pipeline and run it.\n","We start by creating a single node pipeline per *processor*, which we refer as a *task*.\n","Then we combine all 4 *tasks* into a single pipeline by declaring the input/output *dependencies*\n","that exist between *tasks*:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from oneml.processors import PipelineBuilder, PipelineRunner, display_dag\n","\n","a = PipelineBuilder.task(A, \"A\")\n","b = PipelineBuilder.task(B, \"B\")\n","c = PipelineBuilder.task(C, \"C\")\n","d = PipelineBuilder.task(D, \"D\")\n","\n","diamond = PipelineBuilder.combine(\n","    a,\n","    b,\n","    c,\n","    d,\n","    dependencies=(\n","        b.inputs.X << a.outputs.Z1,\n","        c.inputs.X << a.outputs.Z2,\n","        d.inputs.X1 << b.outputs.Z,\n","        d.inputs.X2 << c.outputs.Z,\n","    ),\n","    name=\"diamond\",\n",")\n","\n","display_dag(diamond)  # displays the pipeline\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![png](figures/beginners_8_0.png)\n","\n","We have seen in these examplea that pipelines, whether made from a single node or multiple, expose\n","*inputs* and *outputs*, and we can access them directly to create dependencies between different\n","pipelines.\n","The *left-shift* and *right-shift* notation, i.e., `<<`, `>>`, respectively, are the operators that\n","to create such *dependencies*, which will return a tuple holding the *dependency* information.\n","\n","If the user accesses an input or output that do not exist, or confuses the direction of the\n","dependency, a run-time error will be raised.\n","This is why we have to declare the inputs and outputs of *processors*.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Standardized Logistic Regression Example\n","\n","We are now going to build a standardized logistic example where we have two sources for input,\n","i.e., *train* and *eval*.\n","We will also show how to build pipelines of more than a single node, and how to connect these into\n","larger pipelines.\n","\n","This is the resulting pipeline we want to build:\n","![Standardized Logistic Regrssion](figures/standardized_lr.png)\n","\n","We start by writing the necessary *processors*, which declare inputs and outputs.\n","Note that *processors* can depend on parameters both on the `__init__` and `process` methods, as\n","shown below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import TypedDict\n","\n","StandardizeTrainOut = TypedDict(\n","    \"StandardizeTrainOut\", {\"mean\": float, \"scale\": float, \"Z_train\": float}\n",")\n","StandardizeEvalOut = TypedDict(\"StandardizeEvalOut\", {\"Z_eval\": float})\n","LogisticRegressionTrainOut = TypedDict(\n","    \"LogisticRegressionTrainOut\", {\"model\": tuple[float], \"Z_train\": float}\n",")\n","LogisticRegressionEvalOut = TypedDict(\"LogisticRegressionEvalOut\", {\"Z_eval\": float})\n","\n","\n","class StandardizeTrain:\n","    def process(self, X_train: float) -> StandardizeTrainOut:\n","        ...\n","\n","\n","class StandardizeEval:\n","    def __init__(self, mean: float, scale: float) -> None:\n","        ...\n","\n","    def process(self, X_eval: float) -> StandardizeEvalOut:\n","        ...\n","\n","\n","class LogisticRegressionTrain:\n","    def process(self, X_train: float, Y_train: float) -> LogisticRegressionTrainOut:\n","        ...\n","\n","\n","class LogisticRegressionEval:\n","    def __init__(self, model: tuple[float, ...]) -> None:\n","        ...\n","\n","    def process(self, X_eval: float, Y_eval: float) -> LogisticRegressionEvalOut:\n","        ..."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We create single node pipelines, aka. *tasks*, and combine them, similar to how we did with in the\n","diamond pipeline example, to create `standardization` and `logistic_regression`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from oneml.processors import PipelineBuilder, PipelineRunner\n","\n","stz_train = PipelineBuilder.task(StandardizeTrain, \"stz_train\")\n","stz_eval = PipelineBuilder.task(StandardizeEval, \"stz_eval\")\n","lr_train = PipelineBuilder.task(LogisticRegressionTrain, \"lr_train\")\n","lr_eval = PipelineBuilder.task(LogisticRegressionEval, \"lr_eval\")\n","\n","standardization = PipelineBuilder.combine(\n","    stz_train,\n","    stz_eval,\n","    dependencies=(\n","        stz_eval.inputs.mean << stz_train.outputs.mean,\n","        stz_eval.inputs.scale << stz_train.outputs.scale,\n","    ),\n","    name=\"standardization\",\n",")\n","\n","logistic_regression = PipelineBuilder.combine(\n","    lr_train,\n","    lr_eval,\n","    dependencies=(lr_eval.inputs.model << lr_train.outputs.model,),\n","    name=\"logistic_regression\",\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The next step is to combine both pipelines into a single one and connect all dependencies\n","between them.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from oneml.processors import display_dag\n","\n","standardized_lr = PipelineBuilder.combine(\n","    standardization,\n","    logistic_regression,\n","    name=\"standardized_lr\",\n","    dependencies=(\n","        logistic_regression.inputs.X_train << standardization.outputs.Z_train,\n","        logistic_regression.inputs.X_eval << standardization.outputs.Z_eval,\n","    ),\n",")\n","\n","display_dag(standardized_lr)  # displays the pipeline\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![png](figures/beginners_15_0.png)\n","\n","There are a few points to clarify here.\n","First, combining pipelines of a single node, two nodes or more, are synthactically the same.\n","It does not matter how many nodes a pipeline has, as long as inputs and outputs and dependencies\n","are correctly specified when combining.\n","\n","Second, pipelines can be combined in different order and the resulting pipeline can be the same.\n","In this example, we first built the standardization and logistic_regression pipelines, and then\n","compose these together.\n","It needn't have been so and we show below two alternatives that yield the same result.\n","\n","Third, the *processors* that we defined above do not have conflicting output names, i.e., all\n","output variable names are different.\n","This simplifies the exposition of the example, but in the [intermediate tutorial](intermediate.md)\n","we explain what happens when we combine pipelines that expose the same output variable names."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### A Second Alternative to Standardized Logistic Regression Example\n","\n","As explained before, we built `standardized_lr` by first building `standardization` and\n","`logistic_regression` and then combining them.\n","An alternative is to first build the `train` and `eval` pipelines separately, and then combine.\n","The following code yields the same result as before:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_pipeline = PipelineBuilder.combine(\n","    stz_train,\n","    lr_train,\n","    name=\"train_pipeline\",\n","    dependencies=(lr_train.inputs.X_train << stz_train.outputs.Z_train,),\n",")\n","\n","eval_pipeline = PipelineBuilder.combine(\n","    stz_eval,\n","    lr_eval,\n","    name=\"eval_pipeline\",\n","    dependencies=(lr_eval.inputs.X_eval << stz_eval.outputs.Z_eval,),\n",")\n","\n","standardized_lr = PipelineBuilder.combine(\n","    train_pipeline,\n","    eval_pipeline,\n","    name=\"standardized_lr\",\n","    dependencies=(\n","        eval_pipeline.inputs.mean << train_pipeline.outputs.mean,\n","        eval_pipeline.inputs.scale << train_pipeline.outputs.scale,\n","        eval_pipeline.inputs.model << train_pipeline.outputs.model,\n","    ),\n",")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["There is no difference between `standardize_lr` pipelines obtained from these two procedures, the\n","resulting pipelines are exactly the same."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### A Third Alternative to Standardized Logistic Regression Example\n","\n","A third alternative is to build the whole pipeline in a single combine operation.\n","The only drawback to doing it this way is that pipelines are less modular, in a conceptual sense,\n","to share between users, whereas the first and second approach encapsulate the concepts and make\n","those explicit to share, via standardization / logistic_regression, or via train / eval pipelines,\n","respectively."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["standardized_lr = PipelineBuilder.combine(\n","    stz_train,\n","    lr_train,\n","    stz_eval,\n","    lr_eval,\n","    name=\"standardized_lr\",\n","    dependencies=(\n","        stz_eval.inputs.mean << stz_train.outputs.mean,\n","        stz_eval.inputs.scale << stz_train.outputs.scale,\n","        lr_eval.inputs.model << lr_train.outputs.model,\n","        lr_train.inputs.X_train << stz_train.outputs.Z_train,\n","        lr_eval.inputs.X_eval << stz_eval.outputs.Z_eval,\n","    ),\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Standardized LR with Data\n","\n","The previous `standardized_lr` had unspecified inputs, in particular, `X` and `Y` have been left\n","unspecified.\n","This means that the pipeline is not runnable yet, but if we connect the missing dependencies, the\n","resulting pipeline will be runnable.\n","\n","In terms of results it does not matter the order in which build the pipelines, but encapsulating\n","them as intermediate formulations makes it easier to reuse them.\n","That's why we separated connecting `standardized_lr` to any data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LoadDataOut = TypedDict(\n","    \"LoadDataOut\", {\"X_train\": float, \"X_eval\": float, \"Y_train\": float, \"Y_eval\": float}\n",")\n","\n","\n","class LoadData:\n","    def process(self) -> LoadDataOut:\n","        ...\n","\n","\n","load_data = PipelineBuilder.task(LoadData, \"load_data\")\n","\n","final_pipeline = PipelineBuilder.combine(\n","    load_data,\n","    standardized_lr,\n","    name=\"final_pipeline\",\n","    dependencies=(\n","        standardized_lr.inputs.X_train << load_data.outputs.X_train,\n","        standardized_lr.inputs.X_eval << load_data.outputs.X_eval,\n","        standardized_lr.inputs.Y_train << load_data.outputs.Y_train,\n","        standardized_lr.inputs.Y_eval << load_data.outputs.Y_eval,\n","    ),\n",")\n","\n","display_dag(final_pipeline)  # displays the pipeline\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![png](figures/beginners_23_0.png)"]}],"metadata":{"kernelspec":{"display_name":"oneml-app-HvMeh-nl-py3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"118274ffcdc0169b3c4a867cb488386328c6727e3b0844e9bd2c3e369f2ace34"}}},"nbformat":4,"nbformat_minor":2}
